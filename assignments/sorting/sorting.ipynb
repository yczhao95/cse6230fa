{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Distributed Memory Sorting\n",
    "\n",
    "**Due November 15, 2018**\n",
    "\n",
    "Same logistic rules as Project 1 apply\n",
    "\n",
    "This notebook should be run on a 12-core node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =========================================================================\n",
      "|                                                                         |\n",
      "|       A note about python/3.6:                                          |\n",
      "|       PACE is lacking the staff to install all of the python 3          |\n",
      "|       modules, but we do maintain an anaconda distribution for          |\n",
      "|       both python 2 and python 3. As conda significantly reduces        |\n",
      "|       the overhead with package management, we would much prefer        |\n",
      "|       to maintain python 3 through anaconda.                            |\n",
      "|                                                                         |\n",
      "|       All pace installed modules are visible via the module avail       |\n",
      "|       command.                                                          |\n",
      "|                                                                         |\n",
      " =========================================================================\n"
     ]
    }
   ],
   "source": [
    "module use $CSE6230_DIR/modulefiles\n",
    "module unload cse6230/core\n",
    "module load cse6230/mvapich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- The goal of this project is to *use profiling* to optimize the performance of\n",
    "  an MPI-based library for distributed memory sorting.\n",
    "  - The main library interface is (as declared in [proj2sorter.h](proj2sorter.h)):\n",
    "\n",
    "``` C\n",
    "    /* This is the default implementation of sorting:\n",
    "     * \\param[in] sorter       The sorting context.  Put all of your customizations\n",
    "     *                         in this object.  Defined in proj2sorter_impl.h, where\n",
    "     *                         you can change the struct to include more data\n",
    "     * \\param[in] numKeysLocal The number of keys on this process.\n",
    "     * \\param[in] uniform      True if there are the same number of keys on each process\n",
    "     * \\param[in/out] keys     The input array.  On output, should be globally\n",
    "     *                         sorted in ascending order.\n",
    "     * \\return                 Non-zero if an error occured.\n",
    "     */\n",
    "    int Proj2SorterSort(Proj2Sorter sorter, size_t numKeysLocal, int uniform, uint64_t *keys);\n",
    "```\n",
    "  - The small library comes with some logging and error macros (see\n",
    "      [proj2.h](proj2.h)) as well as an interface for obtaining/restoring workspace\n",
    "      arrays (see `Proj2SorterGetWorkArray()` and `Proj2SorterRestoreWorkArray()` in\n",
    "      [proj2sorter.h](proj2sorter.h).  To be memory neutral, restore every\n",
    "      workspace that you get.\n",
    "\n",
    "  - Functioning parallel implementations have been provided, one based on\n",
    "      [quicksort](https://en.wikipedia.org/wiki/Quicksort#Parallelization) and\n",
    "      one base on [bitonic mergesort](https://en.wikipedia.org/wiki/Bitonic_sorter).\n",
    "\n",
    "  - A [template library](https://github.com/swenson/sort) originated by Chris\n",
    "      Swenson has been imported for a quicksort implementation that is faster\n",
    "      than `qsort` from the standard library.  The template library includes\n",
    "      other implementations that you are welcome to explore.\n",
    "      \n",
    "      If you go through the work of bringing in a serial sorting library, you're welcome to use it,\n",
    "      as long as you put it somewhere the TA and I can access it.\n",
    "\n",
    "  - Indeed, as with previous assignments, the implementation details are up\n",
    "      to you.  As with Checkpoint 1 of the final, there is a test program\n",
    "      ([test_proj2.c](test_proj2.c)), which may not be edited, that calls your\n",
    "      library.  It will test the sorting bandwidth (bytes sorted per second) of\n",
    "      your code on uniformly generated random data at varying numbers of *keys\n",
    "      per MPI process* (a *key* in our library is just a `uint64_t`: a large\n",
    "      integer).  You may incorporate additional files into your library by\n",
    "      adding a `Makefile.inc` file to your project.\n",
    "\n",
    "```\n",
    "    ./test_proj2 MIN_KEYS_PER_PROCESS MAX_KEYS_PER_PROCESS MULTIPLIER SEED NUM_REPS UNIFORM\n",
    "```\n",
    "\n",
    "This means that the test program seeds the random number generator with `SEED`,\n",
    "starts with `MIN_KEYS_PER_PROCESS`, tests `NUM_REPS` times to get an average,\n",
    "and gets the next problem size by multiplying by `MULTIPLIER`, until at most\n",
    "`MAX_KEYS_PER_PROCESS`.  If `UNIFORM` is `0`, then the number of keys per process will vary between `MIN_KEYS_PER_PROCESS` and `2*MIN_KEYS_PER_PROCESS`. In your testing, you will probably want to test **one\n",
    "problem size** at a time.  If you are\n",
    "having problems with correctness (segmentation faults, hangs/deadlocks, etc.),\n",
    "it is best to work those out on your workstation/laptop is possible before\n",
    "using SUs on Stampede2.  You are starting (knock on wood) from a correct\n",
    "implementation: try to work in small changes, testing for correctness at each change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f libproj2.so  proj2.o proj2sorter.o local.o bitonic.o quicksort.o test_proj2.o test_proj2\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o test_proj2.o test_proj2.c\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o proj2.o proj2.c\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o proj2sorter.o proj2sorter.c\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o local.o local.c\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o bitonic.o bitonic.c\n",
      "mpicc -I../../utils/Random123/include -g -Wall -std=c99 -fopenmp -fpic -O3 -c -o quicksort.o quicksort.c\n",
      "mpicc -fopenmp -shared -o libproj2.so proj2.o proj2sorter.o local.o bitonic.o quicksort.o -lm\n",
      "mpicc -fopenmp -L./ -Wl,-rpath,./ -o test_proj2 test_proj2.o -lproj2\n"
     ]
    }
   ],
   "source": [
    "make clean\n",
    "make test_proj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MPI_N=${PBS_NP} # You may use ${PBS_NP} or the largest power of 2 smaller than PBS_NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ./test_proj2 minKeys 80 maxKeys 100000 mult 32 seed 0 uniform 1\n",
      "[0] Testing numKeysLocal 80, numKeysGlobal 960, total bytes 7680\n",
      "[0] Tested numKeysLocal 80, numKeysGlobal 960, total bytes 7680: average bandwidth 5.955302e+07\n",
      "[0] Testing numKeysLocal 2560, numKeysGlobal 30720, total bytes 245760\n",
      "[0] Tested numKeysLocal 2560, numKeysGlobal 30720, total bytes 245760: average bandwidth 1.974408e+08\n",
      "[0] Testing numKeysLocal 81920, numKeysGlobal 983040, total bytes 7864320\n",
      "[0] Tested numKeysLocal 81920, numKeysGlobal 983040, total bytes 7864320: average bandwidth 5.866841e+07\n",
      "[0] Harmonic average bandwidth: 7.711782e+07\n"
     ]
    }
   ],
   "source": [
    "mpirun -n ${MPI_N} ./test_proj2 80 100000 32 0 5 1 # The uniform tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ./test_proj2 minKeys 80 maxKeys 100000 mult 32 seed 0 uniform 0\n",
      "[0] Testing numKeysLocal 145, numKeysGlobal 1496, total bytes 11968\n",
      "[0] Tested numKeysLocal 145, numKeysGlobal 1496, total bytes 11968: average bandwidth 6.177579e+07\n",
      "[0] Testing numKeysLocal 4656, numKeysGlobal 47577, total bytes 380616\n",
      "[0] Tested numKeysLocal 4656, numKeysGlobal 47577, total bytes 380616: average bandwidth 2.304613e+08\n",
      "[0] Testing numKeysLocal 131642, numKeysGlobal 1468879, total bytes 11751032\n",
      "[0] Tested numKeysLocal 131642, numKeysGlobal 1468879, total bytes 11751032: average bandwidth 1.897263e+08\n",
      "[0] Harmonic average bandwidth: 1.162906e+08\n"
     ]
    }
   ],
   "source": [
    "mpirun -n ${MPI_N} ./test_proj2 80 100000 32 0 5 0 # The non-uniform tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "- 0-4 points for hassle-free usage: maximized if the python script made from the notebook runs the first time.\n",
    "    * Points lost if we have to figure out how to reproduce your reported results.\n",
    "- 0-6 points for correctness:\n",
    "    * Whether the notebook runs to\n",
    "      completion (it will abort if a list of keys is not properly sorted).\n",
    "    * You lose half the points if your code is not correct; subsequent points\n",
    "      can be lost for poor code organization.\n",
    "- 0-2 Points for your prediction and the reasoning that goes into it\n",
    "- 0-8 Points for the notebook:\n",
    "    * 0-2 points for how well the notebook tracks your `git` history: did we find the commits\n",
    "      used to generate the entries?  Is there an entry for all the major\n",
    "      aspects of your development?\n",
    "    * 0-3 points for your profiling evidence: is it present?  Does it seem to\n",
    "      indicate what you say it indicates?\n",
    "    * 0-3 points for your planning: do your proposed code changes follow\n",
    "      logically from the evidence?\n",
    "- **2 bonus points** for adapting the code to use the GPUs for sorting\n",
    "      \n",
    "## Prediction\n",
    "\n",
    "Predict, without going under, the highest bandwidth that any student will achieve on this assignment.  Assume only the CPUs are used.  Justify your prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "## Notebook\n",
    "\n",
    "Please put your notebook documenting your measurements, thought processes, models, etc. from your work on this project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
