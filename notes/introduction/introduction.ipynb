{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "span.alg {color: SteelBlue;}\n",
    "span.mch {color: OrangeRed;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSE6230: High Performance Parallel Computing\n",
    "\n",
    "## Welcome!\n",
    "\n",
    "Toby Isaac, [tisaac@cc.gatech.edu](mailto:tisaac@cc.gatech.edu)\n",
    "\n",
    "Zhihang Liu, [zliu354@gatech.edu](mailto:zliu354@gatech.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Richardson's Forecast Factory](images/forecastfactory.jpeg)\n",
    "\n",
    "(Richardson's [forecast factory](https://en.wikipedia.org/wiki/Lewis_Fry_Richardson#Weather_forecasting), via [Peter Lynch](https://maths.ucd.ie/~plynch/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The same principles Richardson would have used for his supercomputer are the ones we need for ours.\n",
    "\n",
    "![Tianhe-2](images/Tianhe-2.jpg)\n",
    "\n",
    "(Via [wikimedia](https://commons.wikimedia.org/wiki/File:Tianhe-2.jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistics\n",
    "\n",
    "The **[Syllabus]** has been posted to the [Canvas] page.  A quick summary:\n",
    "\n",
    "* There is a [poll] to let me know when you're able to come to office hours.\n",
    "\n",
    "[Syllabus]: https://gatech.instructure.com/files/1029360/\n",
    "[Canvas]: https://gatech.instructure.com/courses/26393\n",
    "[poll]: https://goo.gl/forms/NdIBoIk9Dv1dftzF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * There will be compiled-language programming (mostly C) in this course.\n",
    "    Assignment time is best spent learning new tools and trying to understand\n",
    "    performance.  If the new tool you are learning is C, you will not be able to focus\n",
    "    on the purpose of the assignment.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * Grade breakdown is 1/3 exercises (~weekly), 1/3 projects (2-3), 1/3 final project.\n",
    "  \n",
    "  * *Most* assignments can be resubmitted once for up to 85% credit.  If you're late, it's\n",
    "    automatically treated as a resubmission.  See the syllabus for full details.\n",
    "    \n",
    "  * **The cutoff is December 13, 2018 at 11:59 PM, EST** for all assignments.  \n",
    "    Keep this in mind if you are traveling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The syllabus, lecture notes, and all course materials are being kept on the course's\n",
    "[repository] (https://github.gatech.edu/cse6230fa18/cse6230).\n",
    "\n",
    "* All students have access to GT GitHub, but it is behind the firewall :(.  If you are unable\n",
    "  to set up a VPN, let me know.\n",
    "\n",
    "[repository]: https://github.gatech.edu/cse6230fa18/cse6230\n",
    "\n",
    "* Our main computing resource will be the PACE [Instructional Cluster] (pace-ice).  This is also behind the firewall.\n",
    "\n",
    "  - All students are supposed to have access: let me know if by the end of the week you do not.\n",
    "  - You should be able to complete all assignments on pace-ice.  I will set up the software modules you need to run\n",
    "    there.\n",
    "  - You will probably find it convenient to do some development on your laptop/workstation.  All of the software that we\n",
    "    will use is freely available, most of it can be installed by package managers.\n",
    "\n",
    "\n",
    "[Instructional Cluster]: http://pace.gatech.edu/sites/default/files/pace-ice_orientation_1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Guides for getting a copy of the repository and getting set up on pace-ice are in the repo\n",
    "(a bit of a chicken and egg, I know), and (I hope) copies have been posted on Canvas.\n",
    "\n",
    "*Please try to do these things soon.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is this class about?\n",
    "\n",
    "- *Performance measurement*\n",
    "- *Performance modeling*\n",
    "- *Performance engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### You have a problem\n",
    "\n",
    "$$\\text{Solve}\\ A x = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Maybe you have a *big* problem\n",
    "\n",
    "$$\\Huge\\text{Solve}\\ Ax = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### But you have an <span class=\"alg\">algorithm</span>\n",
    "\n",
    "<span class=\"alg\">$$\\begin{aligned}\n",
    "\\alpha_k &\\leftarrow r_{k}^T r_{k} / (p_{k}^T A p_{k}) \\\\\n",
    "x_k &\\leftarrow x_{k} + \\alpha_k p_{k} \\\\\n",
    "r_{k+1} &\\leftarrow r_{k} - \\alpha_k A p_{k} \\\\\n",
    "\\beta_k &\\leftarrow r_{k+1}^T r_{k+1} / r_{k}^T r_{k} \\\\\n",
    "p_{k+1} &\\leftarrow r_{k+1} + \\beta_k p_k \\\\\n",
    "k & \\leftarrow k + 1\n",
    "\\end{aligned}$$</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And a <span class=\"mch\">machine</span>\n",
    "\n",
    "![Ranger](images/TACC-Ranger-cluster.jpg)\n",
    "\n",
    "(Via [wikipedia](https://en.wikipedia.org/wiki/File:TACC-Ranger-cluster.jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### To use the <span class=\"alg\">algorithm</span> on the <span class=\"mch\">machine</span>, it goes through a hierarchy of compilers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* You: (algorithm $\\to$ code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(A, x, b, epsilon):\n",
    "    r = b - A.dot(x)\n",
    "    p = r\n",
    "    while True:\n",
    "        alpha = r.dot(r) / p.dot(A.dot(p))\n",
    "        if alpha < epsilon:\n",
    "            break\n",
    "        x = x + alpha * p\n",
    "        r_new = r - alpha * A.dot(p)\n",
    "        beta = r_new.dot(r_new) / r.dot(r)\n",
    "        p = r_new + beta * p\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Source-to-source: (`.py` $\\to$ {`.c`, `.cu`, ...})\n",
    "\n",
    "```C\n",
    "int\n",
    "_dsolvecg (mat_t *A, int n, double *x, double *b, double epsilon)\n",
    "{\n",
    "    int k;\n",
    "    double *r, *p;\n",
    "    \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Machine-independent intermediate representation; (`.c` $\\to$ `.ll`, `.cu` $\\to$ `.ptx`)\n",
    "\n",
    "```llvm\n",
    "  %2 = urem i64 %0, 27\n",
    "  %3 = udiv i64 %0, 27\n",
    "  %4 = urem i64 %3, 27\n",
    "  %5 = udiv i64 %0, 729\n",
    "  %6 = shl nuw nsw i64 %4, 5\n",
    "  %7 = or i64 %6, %2\n",
    "  %8 = urem i64 %5, 27\n",
    "  %9 = udiv i64 %0, 19683\n",
    "  %10 = shl nuw nsw i64 %8, 10\n",
    "  %11 = or i64 %10, %7\n",
    "  %12 = urem i64 %9, 27\n",
    "  %13 = udiv i64 %0, 531441\n",
    "  %14 = shl nuw nsw i64 %12, 15\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Machine code (finally!): (`.ll` $\\to$ `.o`, `.ptx` $\\to$ `.sass`)\n",
    "\n",
    "```\n",
    "\t.cfi_startproc\n",
    "# BB#0:\n",
    "\tpushq\t%rbx\n",
    ".Lcfi0:\n",
    "\t.cfi_def_cfa_offset 16\n",
    ".Lcfi1:\n",
    "\t.cfi_offset %rbx, -16\n",
    "\tmovq\t%rdi, %r8\n",
    "\tmovabsq\t$-7515340178177965473, %rbx # imm = 0x97B425ED097B425F\n",
    "\tmovq\t%r8, %rax\n",
    "\tmulq\t%rbx\n",
    "\tmovq\t%rdx, %r9\n",
    "\tshrq\t$4, %r9\n",
    "\tleaq\t(%r9,%r9,8), %rax\n",
    "\tleaq\t(%rax,%rax,2), %rax\n",
    "\tmovq\t%r8, %r10\n",
    "\tmovq\t%r8, %rsi\n",
    "\tsubq\t%rax, %rsi\n",
    "\tmovq\t%r9, %rax\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Between your <span class=\"alg\">program</span> and the <span class=\"mch\">machine</span> is the OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "uname -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OS will schedule your program (and many other simultaneously), subject to *environment variables* that\n",
    "can affect the way your program runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ... All before your code is executed by one of the most complex machines ever made\n",
    "\n",
    "![Xeon Phi](images/XeonPhiDie_03.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Your algorithm survives all of *that*...\n",
    "\n",
    "... *and* gives the right answer (hooray!), but you want\n",
    "*higher performance*:\n",
    "\n",
    "* To use less time / less power\n",
    "* To solve a bigger problem\n",
    "* To solve more accurately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Is higher performance possible?\n",
    "* What's the highest performance possible with this algorithm and this machine?\n",
    "* What changes will improve performance?\n",
    "* Will some other machine provide higher performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class we will try to be scientific about answering these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### *Profiling:* We gather data about the way the machine runs our program.\n",
    "\n",
    "Timings, yes, but often more fine-grained information is helpful.\n",
    "\n",
    "- Timings of components of the program in isolation (e.g. the `gprof` utility)\n",
    "- Measurements of components of the machine in isolation (e.g. the `perf` utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### *Modeling:* We construct a model that explains the data.\n",
    "  \n",
    "$$\\LARGE{T_{\\color{SteelBlue}{f}} (\\color{OrangeRed}{P})}$$\n",
    "\n",
    "* The model of performance $T$ depends on the <span class=\"alg\">algorithm</span>\n",
    "  and the <span class=\"mch\">machine</span>\n",
    "* Tradeoffs: describes the data accurately enough, simple enough to analyze and make predictions.\n",
    "\n",
    "> Since all models are wrong the scientist cannot obtain a \"correct\" one by excessive elaboration. On the contrary following William of Occam he should seek an economical description of natural phenomena. Just as the ability to devise simple but evocative models is the signature of the great scientist so overelaboration and overparameterization is often the mark of mediocrity.\n",
    ">\n",
    "> --George Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\"All models are wrong, but some are useful.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### *Engineering:* We use other people's good ideas and tools to improve performance.\n",
    "\n",
    "* In general a performance model will suggest one current *bottleneck* limiting performance.\n",
    "* Tools will be:\n",
    "  - languages\n",
    "  - code design patterns\n",
    "  - compiler directives\n",
    "  - environment variables\n",
    "  - libraries\n",
    "  - everything at our disposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Faster chips will not save us\n",
    "\n",
    "They are not getting faster.  Machines are getting faster by getting more *concurrent*: doing more work in parallel.\n",
    "\n",
    "![40 years of processor trends](images/40-years-processor-trend.png)\n",
    "\n",
    "[Horowitz et al. via C. Batten, updated by K. Rupp](https://www.karlrupp.net/2015/06/40-years-of-microprocessor-trend-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Asymptotically optimal algorithms will not save us\n",
    "\n",
    "Knowing that your algorithm will eventually be the best for a problem size that doesn't fit on your machine is cold comfort.\n",
    "\n",
    "Examples of optimal algorithms that are not currently used in practice:\n",
    "\n",
    "* [Coppersmith-Winograd matrix-matrix multiplication](https://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm):\n",
    "  $O(n^{2.375477})$ vs. practical $O(n^{3})$\n",
    "* Ajtai, Komlós, and Szemerédi (AKS) sorting network: $O(\\log n)$ depth vs. $O(\\log^2 n)$ for, e.g. Batcher's bitonic sort.  If we assume $T_{\\text{AKS}} \\approx 87 \\log_2 n$ and\n",
    "$T_{\\text{Batcher}} = \\frac{1}{2} \\log_2 n (\\log_2 n + 1)$ [Badder, Batcher 2011]:\n",
    "\n",
    "[Badder, Batcher 2011]: https://doi.org/10.1007/978-1-4614-1851-1_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = [10. ** x for x in range(87)]\n",
    "T_AKS = [87. * np.log2(x) for x in X]\n",
    "T_BAT = [0.5 * np.log2(x) * (np.log2 (x) + 1.) for x in X]\n",
    "plt.figure()\n",
    "plt.semilogx(X, T_AKS, label='$T_{AKS}$')\n",
    "plt.semilogx(X, T_BAT, label='$T_{Batcher}$')\n",
    "plt.title(\"Sorting network comparison\")\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Models in this Class\n",
    "\n",
    "This class will roughly be organized around the types of machine models that we use.  As the quote above says, one model isn't better than they other, but each has an appropriate scale where it is useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Processors alone\n",
    "\n",
    "Registers, a scheduler, a functional units\n",
    "\n",
    "![cpu](images/cpu.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Processors and Memory\n",
    "\n",
    "![ram](images/ram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Processors, Memory, & Cache\n",
    "\n",
    "![cache](./images/cache.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Nodes & Networks\n",
    "\n",
    "![net](./images/net.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Machines & People\n",
    "\n",
    "![ENIAC](./images/Classic_shot_of_the_ENIAC.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance Metrics Review\n",
    "\n",
    "This section is best read along side Georg Hager's [Fooling the Masses]\n",
    "\n",
    "[Fooling the Masses]: https://blogs.fau.de/hager/archives/category/fooling-the-masses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Strong Scaling\n",
    "\n",
    "Assume $\\color{OrangeRed}{P}$ describing the machine in $T_{\\color{SteelBlue}{f}}(\\color{OrangeRed}{P})$ measures its concurrency.\n",
    "\n",
    "How does $T_{f}(P)$ change as $\\color{OrangeRed}{P \\to \\infty}$?\n",
    "\n",
    "Some reasonable (but not always true) assumptions:\n",
    "- $T_{f}(P) = \\max_{i} T_{f,i}(P)$, the maximum time spent by any of the parallel components of the machine\n",
    "- $\\max_{i} T_{f,i}(P) \\geq\n",
    "T_{f}(1) / P$.  This is reasonable assuming we start from an efficient serial algorithm. (Why?)\n",
    "- Therefore\n",
    "$$\\Large T_{f}(P) \\geq \\color{SeaGreen}{T_{f}(1) / P}.$$  If this is an equality, it is sometimes called <span style='color:SeaGreen'>**perfect strong scaling**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Three ways to visualize strong scaling\n",
    "\n",
    "- $\\large T_{f}(P)$ itself: \"runtime\"\n",
    "- $\\large S_{f}(P) := T_{f}(1) / T_{f}(P)$: \"speedup\"\n",
    "- $\\large H_{f}(P) := T_{f}(1) / (P T_{f}(P))$: \"strong-scaling efficiency\"\n",
    "\n",
    "Why might we prefer to visualize one more than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "P = np.array(range(1,101))\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "ax1.loglog(P,1. / P,':')\n",
    "ax1.fill_between(P,1. / P, np.ones(100), facecolor='gray', alpha=0.25)\n",
    "ax1.set_title('$T_f(P) / T_f(1)$')\n",
    "ax2.loglog(P,P,':')\n",
    "ax2.fill_between(P,np.ones(100), P, facecolor='gray', alpha=0.25)\n",
    "ax2.set_title('$S_f(P) = T_f(1) / T_f(P)$')\n",
    "ax3.semilogx(P,np.ones(100),':')\n",
    "ax3.fill_between(P,np.zeros(100),np.ones(100), facecolor='gray', alpha=0.25)\n",
    "ax3.set_title('$H_f(P) = T_f(1) / (P\\cdot T_f(P))$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Amdahl's Law\n",
    "\n",
    "Amdahl's law describes strong scalability under the assumption that $T_f(1)$ is composed\n",
    "of a non-parallelizable fraction $\\color{red}{\\alpha}$, and a perfectly-parallelizable remainder.\n",
    "\n",
    "$$\\Large T_f(P) = \\color{red}{\\alpha} T_f(1) + (1 - \\color{red}{\\alpha}) \\frac{T_f(1)}{P}.$$\n",
    "\n",
    "This implies \n",
    "\n",
    "$$\\large S_f(P) = \\frac{1}{\\color{red}{\\alpha} + (1 - \\color{red}{\\alpha})\\frac{1}{P}}\n",
    "\\leq \\frac{1}{\\color{red}{\\alpha}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(range(1,101))\n",
    "alpha = [0.5,0.25,0.125,0.0625]\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "for a in alpha:\n",
    "    T = a + (1.-a) / P\n",
    "    ax1.loglog(P,T)\n",
    "    ax2.loglog(P,1./T)\n",
    "    ax3.semilogx(P,1./(P * T),label='$\\\\alpha =$ ' +str(a))\n",
    "ax1.set_title('$T_f(P) / T_f(1)$')\n",
    "ax2.set_title('$S_f(P)$')\n",
    "ax3.set_title('$H_f(P)$')\n",
    "ax3.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scalability is not Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = range(1,101)\n",
    "alpha_1 = 0.2\n",
    "alpha_2 = 0.1 # A smaller serial fraction!\n",
    "T_1_0 = 1.\n",
    "T_2_0 = 4. # A less efficient serial algorithm\n",
    "T_1 = [alpha_1 * T_1_0 + (1. - alpha_1) * T_1_0 / p for p in P]\n",
    "T_2 = [alpha_2 * T_2_0 + (1. - alpha_2) * T_2_0 / p for p in P]\n",
    "S_1 = [T_1[0] / T_1[p] for p in range(100)]\n",
    "S_2 = [T_2[0] / T_2[p] for p in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(P,S_1,label=\"Algorithm 1\")\n",
    "plt.plot(P,S_2,label=\"Algorithm 2\")\n",
    "plt.title(\"Speedup\")\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(P,T_1,label=\"Algorithm 1\")\n",
    "plt.loglog(P,T_2,label=\"Algorithm 2\")\n",
    "plt.title(\"Runtime\")\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Weak Scaling\n",
    "\n",
    "Suppose that our algorithm can be used on a class of problems indexed by their size,\n",
    "$\\color{SeaGreen}{N}$.\n",
    "\n",
    "$$\\LARGE{T_{\\color{SteelBlue}{f}} (\\color{SeaGreen}{N},\\color{OrangeRed}{P})}$$\n",
    "\n",
    "- By the same assumptions as before $T_f(kN, kP) \\geq \\frac{1}{k} T_f(kN, P) = \\beta T_f (N, P)$,\n",
    "  where\n",
    "  \n",
    "  $$\\large \\color{red}{\\beta = \\frac{T_f(kN,P)}{k T_f(N,P)}}.$$\n",
    "  \n",
    "- We assume $T_f(N,P) \\in \\Theta(N)$ (otherwise, under mild assumptions, we can reindex, e.g.,\n",
    "  if $T_f(N,P) \\in \\Theta(N^3)$, index by $T_f(\\hat{N},P)$, where $\\hat{N}:=N^3$)\n",
    "- This implies $\\beta\\approx 1$.\n",
    "- We thus define <span style='color:SeaGreen'>**perfect weak scaling**</span> by\n",
    "\n",
    "$$\\large\\color{SeaGreen}{T_f(k N, k P) = T_f (N, P)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The most common ways to visualize weak scaling are, for fixed $N$\n",
    "\n",
    "- $\\large T_f (PN, P)$: \"runtime\"\n",
    "- $\\large E_f (N, P) = T_f (N, 1) / \\large T_f (PN, P)$: \"weak-scaling efficiency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(range(1,101))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.semilogx(P,np.ones(100),':')\n",
    "ax1.fill_between(P,np.ones(100), 2. * np.ones(100), facecolor='gray', alpha=0.25)\n",
    "ax1.set_title('$T_f(PN,P) / T_f(N,1)$')\n",
    "ax2.semilogx(P,np.ones(100),':')\n",
    "ax2.fill_between(P,np.zeros(100),np.ones(100), facecolor='gray', alpha=0.25)\n",
    "ax2.set_title('$E_f(N,P) = T_f(N,1) / (T_f(PN,P))$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Of course, since $T_f(N,P)$ now has two parameters, should we be suspicious if we only see one line?\n",
    "\n",
    "Suppose, as is often the case, that *parallelization has overhead*:\n",
    "\n",
    "$$\\large T_f(N,P) = \\log P + \\frac{N}{P}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(range(1,101))\n",
    "N = [1, 10, 100, 1000]\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "for n in N:\n",
    "    T = np.log(P) + n\n",
    "    ax1.semilogx(P,T / T[0])\n",
    "    ax2.semilogx(P,T[0] /T,label='$N =$ ' +str(n))\n",
    "ax1.set_title('$T_f(PN,P) / T_f(N,1)$')\n",
    "ax2.set_title('$E_f(N,P)$')\n",
    "ax2.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numerical Algorithms & Error Tolerance\n",
    "\n",
    "In scientific computing, we often solve problems only approximately, to within some prescribed *error tolerance*:\n",
    "\n",
    "$$\\LARGE{T_{\\color{SteelBlue}{f}} (\\color{SeaGreen}{N},\\color{OrangeRed}{P},\\color{Purple}{\\epsilon})}$$\n",
    "\n",
    "- Different numerical methods often have different convergence rates:\n",
    "\n",
    "$$\\large T_{f_1}(N,P,\\epsilon) \\in O(\\epsilon^{-1})$$\n",
    "\n",
    "$$\\large T_{f_2}(N,P,\\epsilon) \\in O(\\epsilon^{-2})$$\n",
    "\n",
    "- But methods with higher convergence rates may not have as much natural concurrency.  It get's complicated,\n",
    "  and different approaches can be optimal for different parameter sets (see [Pareto optimality](https://en.wikipedia.org/wiki/Pareto_efficiency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Two common dual criteria:\n",
    "\n",
    "  1. Which algorithm and machine can get me $\\epsilon_{\\max}$ accuracy fastest? \n",
    "  \n",
    "  $$\\min_{f,P} T_f(N,P,\\epsilon)\\text{ such that } \\epsilon < \\epsilon_{\\max}$$\n",
    "  \n",
    "  2. Which algorithm and machine minimizes $\\epsilon$ for $T_f < T_{\\max}$?\n",
    "  \n",
    "  $$\\min_{f,P} \\epsilon\\text{ such that } T_f(N,P,\\epsilon) < T_{\\max}$$\n",
    "\n",
    "- An interesting recent example of taking all of these things into account: [Chang et al., to appear](https://arxiv.org/pdf/1705.03625.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### If you've heard of one measurement of performance, it's probably *Flop/s*\n",
    "\n",
    "- Short for \"Floating Point Operations per Second\"\n",
    "\n",
    "- It is a measure of the rate at which a machine is working to solve a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A measure, not *the* measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "FLOPs is the measure used in ranking the Top500 list:\n",
    "\n",
    "![top500.org](images/top500.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Question: the Top500 list measures a machines flop/s doing *what?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Answer: computing the [HPLinpack Benchmark](https://en.wikipedia.org/wiki/LINPACK_benchmarks#HPLinpack), i.e.\n",
    "solving an enormous dense linear system $Ax=b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Okay, so the biggest machines in the world have ~100 Petaflop/s at their disposal\n",
    "\n",
    "What do we have in this class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Good question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How many flop/s do I have on my laptop?\n",
    "\n",
    "First, I should find out what kind of processors I have in my laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hmm, flop/s are not listed anywhere, but I've determined that I have an `Intel Core i5-7200U` chip.  Now I go over to [ark.intel.com](https://ark.intel.com) to see if Intel will tell me. (The `7` in `7200U` indicates that it is a seventh generation chip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hmm, Intel did tell me what the peak frequency of my chip is (3.1 GHz), and how many cores I have (2) but it did not tell me how many flop/s my chip has.  Luckily, they did tell me what the name of my chip was (\"Products formerly *Kaby Lake*\").\n",
    "\n",
    "Maybe the kind strangers at [wikipedia:Instructions Per Cycle](https://en.wikipedia.org/wiki/Instructions_per_cycle) have some information about Kaby Lake processors for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wikipedia says that my Kaby Lake processor gets 32 single precision floating point instructions per cycle. (That page is not well sourced, but next class we'll talk about where that number comes from).\n",
    "\n",
    "So, with 2 cores, 32 flop/s per cycle per core, and 3.1 Gigacycles per second,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 32 * 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the prediction of this convoluted search was that my laptop can get 198 Gigaflop/s:\n",
    "I have a $\\mu$-top500 machine at my fingertips.\n",
    "\n",
    "Does that settle it?  Or should we give credence to what I can actually achieve in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That leads us to our first assignment..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
